{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 研究の流れ\n",
    "\n",
    "この ipynb と README.md を見るだけで流れがわかるようにしました。  \n",
    "なお、各処理の詳細が知りたい場合は各ファイル、Docstring, [README.md](./README.md), [Notion](https://vizlabstudent.notion.site/de778517ea47444c9598d1f5147d78da?v=9dd0c88c9540426db2fa5a4308baf536&pvs=4)を閲覧してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用モジュールの一覧\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "from logging import getLogger\n",
    "from math import floor\n",
    "from struct import pack\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from flask import Flask, Response, jsonify, request\n",
    "from flask_cors import CORS\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from torch import cuda\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ディレクトリの定義\n",
    "from src.config.params import DATASETS, IMAGE_PATH, IMG_SHAPE, LABELS, ML_DATA_DIR, ML_MODEL_DIR, ML_RESULT_DIR, ROOT_DIR, SIDES, SNAP_PATH, SRC_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. フォルダ作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([ROOT_DIR + \"/etc/BasePath.bat\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データの加工\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 元データを各種パラメータに分割する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import subprocess\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.config.params import ROOT_DIR, SNAP_PATH, SRC_PATH, DATASETS, VARIABLE_PARAMETERS\n",
    "from src.Processing.separater.separatorLoop import move_file, rename_file, set_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの定義\n",
    "items1 = VARIABLE_PARAMETERS.copy()\n",
    "items2 = [\"magfield1\", \"magfield2\", \"magfield3\", \"velocity1\", \"velocity2\", \"velocity3\"]\n",
    "xyz = {1: \"x\", 2: \"y\", 3: \"z\"}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    ij = set_ij(dataset)\n",
    "    if ij:\n",
    "        i, j = ij  # type: ignore\n",
    "    else:\n",
    "        print(\"Value Error\", \"入力したデータセットは使用できません\")\n",
    "        sys.exit()\n",
    "\n",
    "    # ログの保存先\n",
    "    files = glob(ROOT_DIR + f\"/data/ICh.dataset=50.ares=1.0d-{i}.adiffArt=1.0d-{j}.h00.g00.BCv1=0.0/Snapshots/*\")\n",
    "    for file in files:\n",
    "        # 元データの分割処理の実行\n",
    "        subprocess.run([SRC_PATH + \"/Processing/cln/separator.exe\", f\"{file}\"])\n",
    "        _, _, _, param, job = map(lambda x: int(x) if x.isnumeric() else x, os.path.basename(file).split(\".\"))\n",
    "        print(\"OPEN\", f\"File snap{i}{j}.{param:02d}.{job:02d}\")\n",
    "\n",
    "        # 出力されたファイル名の変更\n",
    "        for item2 in items2:\n",
    "            if os.path.exists(item2):\n",
    "                rename_file(xyz, item2)\n",
    "\n",
    "            else:  # 見つからない場合\n",
    "                print(\"NotFound\", f\"ファイル {item2}.{param:02d}.{job:02d}\")\n",
    "\n",
    "        # 出力されたファイルの移動\n",
    "        for item1 in items1:\n",
    "            if os.path.exists(item1):\n",
    "                move_file(dataset, param, job, item1)\n",
    "\n",
    "            else:  # 見つからない場合\n",
    "                print(\"NotFound\", f\"ファイル {item1}.{param:02d}.{job:02d}\")\n",
    "\n",
    "        print(\"CLOSE\", f\"File snap{i}{j}.{param:02d}.{job:02d}\")\n",
    "\n",
    "    # coordn を最後に移動させる\n",
    "    for i in range(1, 4):\n",
    "        shutil.move(\"coord\" + xyz[i], SNAP_PATH + f\"/snap{dataset}\")\n",
    "\n",
    "    print(\"END\", \"処理終了\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 バイナリを .npy に変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.config.params import SNAP_PATH, VARIABLE_PARAMETERS, set_dataset\n",
    "from src.Processing.snap2npy import snap2npy\n",
    "from src.Visualization.Visualize.SnapData import SnapData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "sp = SnapData()\n",
    "for param in VARIABLE_PARAMETERS:\n",
    "    for path in glob(SNAP_PATH + f\"/snap{dataset}/{param}/*/*\"):\n",
    "        # 元データを2つに分割\n",
    "        snap2npy(sp, path, dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 可視化\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 各種可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.config.params import SNAP_PATH\n",
    "from src.Visualization.Visualize.Plot import PlotMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "target_path = SNAP_PATH + f\"/snap{dataset}\"\n",
    "viz = PlotMethod(dataset)\n",
    "\n",
    "files = {}\n",
    "\n",
    "# 速度場の可視化\n",
    "files[\"density\"] = glob(target_path + f\"/density/*/*\")\n",
    "files[\"velocityx\"] = glob(target_path + f\"/velocityx/*/*\")\n",
    "files[\"velocityy\"] = glob(target_path + f\"/velocityy/*/*\")\n",
    "for dens_path, vx_path, vy_path in zip(files[\"density\"], files[\"velocityx\"], files[\"velocityy\"]):\n",
    "    viz.drawEnergy_for_velocity(dens_path, vx_path, vy_path)\n",
    "\n",
    "# 磁場の可視化\n",
    "files[\"magfieldx\"] = glob(target_path + f\"/magfieldx/*/*\")\n",
    "files[\"magfieldy\"] = glob(target_path + f\"/magfieldy/*/*\")\n",
    "for magx_path, magy_path in zip(files[\"magfieldx\"], files[\"magfieldy\"]):\n",
    "    viz.drawEnergy_for_magfield(magx_path, magy_path)\n",
    "\n",
    "# HeatMap\n",
    "files[\"enstrophy\"] = glob(target_path + f\"/enstrophy/*/*\")\n",
    "for target in [\"velocityx\", \"velocityy\", \"magfieldx\", \"magfieldy\", \"density\", \"enstrophy\"]:\n",
    "    for path in files[target]:\n",
    "        viz.drawHeatmap(path)\n",
    "        viz.drawEdge(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 AVS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 StreamLines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 LIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.config.params import SNAP_PATH, IMAGE_PATH, SRC_PATH, DATASETS, set_dataset\n",
    "from src.Visualization.LIC.LIC import LicMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "side = \"left\"  # right\n",
    "\n",
    "if dataset not in DATASETS:\n",
    "    print(\"ERROR\", \"このデータセットは使用できません\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"START\", f\"{dataset}.{side.split('_')[1]} 開始\")\n",
    "\n",
    "if not os.path.exists(SRC_PATH + \"/Visualization/LIC/LIC.exe\"):\n",
    "    raise FileNotFoundError\n",
    "\n",
    "lic = LicMethod()\n",
    "\n",
    "# 入出力用path の作成\n",
    "base_out_path = IMAGE_PATH + f\"/LIC/snap{dataset}/{side.split('_')[1]}\"  # ./images/LIC/snap77/left\n",
    "lic.makedir(f\"/LIC/snap{dataset}/{side.split('_')[1]}\")\n",
    "\n",
    "# バイナリファイルの取得\n",
    "binary_paths = glob(SNAP_PATH + f\"/{side}/snap{dataset}/magfieldx/*/*.npy\")\n",
    "file_count = len(binary_paths)\n",
    "\n",
    "# ファイルが無い場合\n",
    "if file_count == 0:\n",
    "    print(\"ERROR\", \"File not Found\")\n",
    "    sys.exit()\n",
    "\n",
    "for xfile in binary_paths:\n",
    "    print(\"START\", f\"{os.path.splitext(os.path.basename(xfile))[0]} 開始\")\n",
    "    file_name = os.path.splitext(os.path.basename(xfile.replace(\"magfieldx\", \"magfield\")))\n",
    "    out_path = base_out_path + f\"/lic_snap{dataset}.{os.path.basename(base_out_path)}.{file_name[0]}.bmp\"\n",
    "    # print(out_path) # ./IMAGE_PATH/LIC/snap77/left/lic_snap77.left.magfield.01.14.bmp\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        yfile = xfile.replace(\"magfieldx\", \"magfieldy\")\n",
    "        props = lic.set_command(xfile, yfile, out_path)\n",
    "        # 引数の作成\n",
    "        # 実行 (1画像20分程度)\n",
    "        lic.LIC(props)\n",
    "\n",
    "        # temp ファイルの削除\n",
    "        lic.delete_tempfile(props[1], props[2])\n",
    "\n",
    "    print(\"END\", f\"{os.path.splitext(os.path.basename(xfile))[0]} 終了\")\n",
    "\n",
    "print(\"END\", f\"{dataset} 終了\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 教師データの作成\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1 ビューワの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.Processing.viewer.createViewer import _sort_paths\n",
    "from src.config.params import IMAGE_PATH, SRC_PATH, SIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in SIDES:\n",
    "    # paths = _sort_paths(paths) # snapの命名規則をもとに時系列順に並び変える。\n",
    "    paths = glob(IMAGE_PATH + f\"/LIC/snap{dataset}/{size}/*.bmp\")\n",
    "    paths_sorted = _sort_paths(paths)\n",
    "\n",
    "    # viewer用のファイル列を作成する\n",
    "    path_list_str = \"\\n\"\n",
    "    for path in paths_sorted:\n",
    "        path_str = path.replace(\"\\\\\", \"/\")\n",
    "        path_list_str += f\"\\t\\t\\t'{path_str}', \\n\"\n",
    "\n",
    "    # html の読み込み\n",
    "    with open(SRC_PATH + \"/Processing/viewer/template/viewer_template.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    # 可視化した.bmpのpathの一覧をhtml に追記\n",
    "    html = html.replace(\"{ replaceblock }\", path_list_str)\n",
    "\n",
    "    # html の保存\n",
    "    out_name = SRC_PATH + f\"/Processing/viewer/template/lic_viewer{dataset}.{size}.html\"\n",
    "    with open(out_name, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2 画像の分割\n",
    "\n",
    "`python ./src/Processing/viewer/writer.py`  \n",
    "を実行し、  \n",
    "`./src/Processing/viewer/template/lic_viewer77.html`\n",
    "を Web で開く (Drug & Drop)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 データの切り取り\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.config.params import set_dataset, SIDES\n",
    "from src.Processing.train.fusion_npy import CreateTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "path = ML_DATA_DIR + \"/LIC_labels/snap_labels.json\"\n",
    "if not os.path.exists(path):\n",
    "    raise ValueError(\"File not found\")\n",
    "\n",
    "md = CreateTrain(dataset)\n",
    "for val in [\"magfieldx\", \"magfieldy\", \"velocityx\", \"velocityy\", \"density\"]:\n",
    "    for side in SIDES:\n",
    "        for label in range(3):\n",
    "            md.cut_and_save_from_json(path, side, label, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. データの合成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from src.config.params import ML_DATA_DIR, LABELS, set_dataset\n",
    "from src.Processing.train.fusion_npy import CreateTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "md = CreateTrain(dataset)\n",
    "props_params = [\n",
    "    ([\"magfieldx\", \"magfieldy\"], \"mag_tupledxy\", md.kernel_listxy),\n",
    "    ([\"velocityx\", \"velocityy\", \"density\"], \"energy\", md.kernel_Energy),\n",
    "]\n",
    "\n",
    "# /images/0131_not/density/density_49.50.8_9.528\n",
    "OUT_DIR = ML_DATA_DIR + f\"/snap{dataset}\"\n",
    "for val_params, out_basename, kernel in props_params:\n",
    "    print(\"START\", val_params)\n",
    "    for label in LABELS.values():  # n, o, x\n",
    "        print(\"START\", f\"label : {label}\")\n",
    "        npys_path = OUT_DIR + f\"/point_{label}\"\n",
    "\n",
    "        for img_path in glob(npys_path + f\"/{val_params[0]}/*.npy\"):\n",
    "            im_list = md.loadBinaryData(img_path, val_params)  # 混合データのロード\n",
    "            result_img = kernel(*im_list)  # データの作成\n",
    "\n",
    "            # 保存先のパスの作成\n",
    "            # /MLdata/snap{dataset}/{out_basename}/{out_basename}_{dataset}.{param}.{job}_{centerx}.{centery}.npy\n",
    "            # /MLdata/snap77/energy/energy_77.01.03_131.543.npy\n",
    "            out_path = npys_path + f\"/{out_basename}/{os.path.basename(img_path).replace(val_params[0], out_basename)}\"\n",
    "            md.save_Data(result_img, out_path)  # データの保存\n",
    "\n",
    "        print(\"END\", f\"label : {label}\")\n",
    "    print(\"END\", val_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 機械学習\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 機械学習\n",
    "- KMeans\n",
    "- kneighbors\n",
    "- linearSVC\n",
    "- rbfSVC\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.MachineLearning.Training import SupervisedML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用パラメータ設定\n",
    "# from src.config.params import ML_PARAM_DICT\n",
    "\n",
    "ML_PARAM_DICT = {\n",
    "    \"KMeans\": {\"n_clusters\": 3, \"n_init\": 10, \"max_iter\": 300, \"tol\": 1e-04, \"random_state\": 100, \"verbose\": 10},\n",
    "    \"kneighbors\": {\"n_clusters\": 3, \"n_init\": 10, \"max_iter\": 300, \"tol\": 1e-04, \"random_state\": 100, \"verbose\": 10},\n",
    "    \"linearSVC\": {\"C\": 0.3, \"random_state\": 0, \"verbose\": 10},\n",
    "    \"rbfSVC\": {\n",
    "        \"C\": 1.0,  # 正則化パラメータ、マージン\n",
    "        \"cache_size\": 200,  # キャッシュサイズ\n",
    "        \"coef0\": 0.0,  # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "        \"decision_function_shape\": \"ovr\",\n",
    "        \"degree\": 3,  # 多項式(poly)カーネルの次数\n",
    "        \"gamma\": \"scale\",  # カーネルの係数、ガウスカーネル(rbf): 1/(n_features * X.var()) と シグモイドカーネル(sigmoid): 1 /n_features\n",
    "        \"kernel\": \"rbf\",  # カーネル('linear', 'poly', 'rbf', 'sigmoid', 'precomputed')\n",
    "        \"max_iter\": -1,  # ソルバー内の反復に対するハード制限\n",
    "        \"probability\": False,  # True の場合、予測時に各クラスに属する確率を返す\n",
    "        \"random_state\": None,  # 乱数の seed値\n",
    "        \"shrinking\": True,  # 縮小ヒューリスティックを使用するかどうか\n",
    "        \"tol\": 0.001,  # 停止基準の許容値\n",
    "        \"verbose\": 2,  # 詳細な出力を有効化\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"colsample_bytree\": 0.4,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 4,\n",
    "        \"missing\": -1,\n",
    "        \"n_estimators\": 1000,\n",
    "        \"subsample\": 0.8,\n",
    "        \"params\": {},\n",
    "        \"verbose\": 50,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本情報\n",
    "mode = \"mixsep\"\n",
    "parameter = \"density\"\n",
    "clf_name = \"XGBoost\"  # \"KMeans\", \"kneighbors\", \"linearSVC\", \"rbfSVC\", \"XGBoost\"\n",
    "\n",
    "# 教師データ用パラメータ\n",
    "pca = False\n",
    "test_size = 0.3\n",
    "model_random_state = 100\n",
    "\n",
    "print(\"PARAMETER : \", f\"name={clf_name}, mode={mode}, parameter={parameter}, pca={pca}, test_size={test_size}, random_state={model_random_state}\")\n",
    "\n",
    "# 機械学習用パラメータ\n",
    "param_dict = ML_PARAM_DICT[clf_name]\n",
    "\n",
    "print(\"LOAD      : \", \"データの読み込み\")\n",
    "model = SupervisedML.load_npys(mode=mode, parameter=parameter, pca=pca, test_size=test_size, random_state=model_random_state)\n",
    "\n",
    "print(\"Learning  : \", f\"学習開始 ({clf_name})\")\n",
    "model.do_learning(clf_name=clf_name, param_dict=param_dict)\n",
    "\n",
    "print(\"SAVE      : \", \"学習結果の保存\")\n",
    "model.save_model()\n",
    "\n",
    "print(\"PREDICT   : \", \"予測\")\n",
    "model.predict()\n",
    "\n",
    "print(\"END       : \", \"処理終了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOAD\", f\"モデルの読み込み ({clf_name})\")\n",
    "model = SupervisedML.load_model(parameter, mode=mode, name=clf_name, model_random_state=model_random_state, param_dict=param_dict)\n",
    "\n",
    "print(\"PREDICT\", \"予測\")\n",
    "model.predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.MachineLearning.CNN import CnnTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20\n",
    "\n",
    "model = CnnTrain()\n",
    "model.set_net()\n",
    "model.set_train(seed=100)\n",
    "model.run(epoch_cnt=EPOCH, do_plot=True)\n",
    "model.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_kn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
