{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 研究の流れ\n",
    "\n",
    "この ipynb と README.md を見るだけで流れがわかるようにしました。  \n",
    "なお、各処理の詳細が知りたい場合は各ファイル、Docstring, [README.md](./README.md), [Notion](https://vizlabstudent.notion.site/de778517ea47444c9598d1f5147d78da?v=9dd0c88c9540426db2fa5a4308baf536&pvs=4)を閲覧してください。\n",
    "\n",
    "※1 /Magnetic を作業ディレクトリとしてください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用モジュールの一覧\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "from logging import getLogger\n",
    "from math import floor\n",
    "from struct import pack\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from flask import Flask, Response, jsonify, request\n",
    "from flask_cors import CORS\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from torch import cuda\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ディレクトリの定義\n",
    "from src.config.params import DATASETS, IMAGE_PATH, LABELS, ML_DATA_DIR, ROOT_DIR, SIDES, SNAP_PATH, SRC_PATH, VARIABLE_PARAMETERS, set_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用する自作モジュール\n",
    "from src.MachineLearning.CNN import CnnTrain\n",
    "from src.MachineLearning.Training import SupervisedML\n",
    "from src.processing.separator.separatorLoop import move_file, rename_file, set_ij\n",
    "from src.processing.snap2npy import snap2npy\n",
    "from src.processing.train.fusion_npy import CreateTrain\n",
    "from src.processing.train.make_train import _create_json, _set_default, _set_n, _set_xo\n",
    "from src.processing.viewer.createViewer import _sort_paths\n",
    "from src.visualization.LIC.LIC import LicMethod\n",
    "from src.visualization.visualize.Plot import PlotMethod\n",
    "from src.visualization.visualize.SnapData import SnapData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. フォルダ作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from src.config.params import BIN_PATH\n",
    "\n",
    "subprocess.run([BIN_PATH + \"/BasePath.bat\"], check=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データの加工\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 元データを各種パラメータに分割する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from src.config.params import ROOT_DIR, SNAP_PATH, SRC_PATH, VARIABLE_PARAMETERS\n",
    "from src.processing.separator.separatorLoop import move_file, rename_file, set_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの定義\n",
    "items1 = VARIABLE_PARAMETERS.copy()\n",
    "items2 = [\"magfield1\", \"magfield2\", \"magfield3\", \"velocity1\", \"velocity2\", \"velocity3\"]\n",
    "xyz = {1: \"x\", 2: \"y\", 3: \"z\"}\n",
    "\n",
    "for dataset in [77, 497, 4949]:\n",
    "    ij = set_ij(dataset)\n",
    "    i, j = ij  # type: ignore\n",
    "\n",
    "    # ログの保存先\n",
    "    files = glob(ROOT_DIR + f\"/data/ICh.target=50.ares=1.0d-{i}.adiffArt=1.0d-{j}.h00.g00.BCv1=0.0/Snapshots/*\")\n",
    "    for file in files:\n",
    "        # 元データの分割処理の実行\n",
    "        subprocess.run([SRC_PATH + \"/Processing/separator/separator.exe\", f\"{file}\"], check=False)\n",
    "        _, _, _, param, job = map(lambda x: int(x) if x.isnumeric() else x, os.path.basename(file).split(\".\"))\n",
    "\n",
    "        # 出力されたファイル名の変更\n",
    "        for item2 in items2:\n",
    "            if os.path.exists(item2):\n",
    "                rename_file(xyz, item2)\n",
    "\n",
    "        # 出力されたファイルの移動\n",
    "        for item1 in items1:\n",
    "            if os.path.exists(item1):\n",
    "                move_file(dataset, param, job, item1)\n",
    "\n",
    "    # coordn を最後に移動させる\n",
    "    for i in range(1, 4):\n",
    "        shutil.move(\"coord\" + xyz[i], SNAP_PATH + f\"/snap{dataset}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 バイナリを .npy に変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from src.config.params import SNAP_PATH, VARIABLE_PARAMETERS\n",
    "from src.processing.snap2npy import snap2npy\n",
    "from src.visualization.visualize.SnapData import SnapData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 77  # 77, 497, 4949\n",
    "\n",
    "sp = SnapData()\n",
    "for param in VARIABLE_PARAMETERS:\n",
    "    for path in glob(SNAP_PATH + f\"/snap{dataset}/{param}/*/*\"):\n",
    "        # 元データを2つに分割\n",
    "        snap2npy(sp, path, dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 可視化\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 各種可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from src.config.params import SNAP_PATH, DATASETS\n",
    "from src.visualization.visualize.Plot import PlotMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    target_path = SNAP_PATH + f\"/snap{dataset}\"\n",
    "\n",
    "    # インスタンスの生成\n",
    "    viz = PlotMethod(dataset)\n",
    "\n",
    "    files = {}  # glob した path の保存\n",
    "\n",
    "    # エネルギーの速さと密度の可視化\n",
    "    files[\"density\"] = glob(target_path + \"/density/*/*\")\n",
    "    files[\"velocityx\"] = glob(target_path + \"/velocityx/*/*\")\n",
    "    files[\"velocityy\"] = glob(target_path + \"/velocityy/*/*\")\n",
    "    for dens_path, vx_path, vy_path in zip(files[\"density\"], files[\"velocityx\"], files[\"velocityy\"], strict=True):\n",
    "        viz.drawEnergy_for_velocity(dens_path, vx_path, vy_path)\n",
    "\n",
    "    # エネルギーの磁場の可視化\n",
    "    files[\"magfieldx\"] = glob(target_path + \"/magfieldx/*/*\")\n",
    "    files[\"magfieldy\"] = glob(target_path + \"/magfieldy/*/*\")\n",
    "    for magx_path, magy_path in zip(files[\"magfieldx\"], files[\"magfieldy\"], strict=True):\n",
    "        viz.drawEnergy_for_magfield(magx_path, magy_path)\n",
    "\n",
    "    # Heatmap と edge の可視化\n",
    "    files[\"enstrophy\"] = glob(target_path + \"/enstrophy/*/*\")\n",
    "    for val_param in [\"velocityx\", \"velocityy\", \"magfieldx\", \"magfieldy\", \"density\", \"enstrophy\"]:\n",
    "        for path in files[val_param]:\n",
    "            viz.drawHeatmap(path)\n",
    "            viz.drawEdge(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 AVS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 StreamLines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 LIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from src.config.params import IMAGE_PATH, SNAP_PATH\n",
    "from src.visualization.LIC.LIC import LicMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 77  # 77, 497, 4949\n",
    "side = \"left\"  # right\n",
    "\n",
    "print(\"START\", f\"{dataset}.{side} 開始\")\n",
    "lic = LicMethod()\n",
    "\n",
    "# 入出力用path の作成\n",
    "base_out_path = IMAGE_PATH + f\"/LIC/snap{dataset}/{side}\"  # ./images/LIC/snap77/left\n",
    "lic.makedir(f\"/LIC/snap{dataset}/{side}\")\n",
    "\n",
    "# バイナリファイルの取得\n",
    "binary_paths = glob(SNAP_PATH + f\"/half_{side}/snap{dataset}/magfieldx/*/*.npy\")\n",
    "file_count = len(binary_paths)\n",
    "\n",
    "for xfile in binary_paths:\n",
    "    print(\"START\", f\"{os.path.splitext(os.path.basename(xfile))[0]} 開始\")\n",
    "    file_name = os.path.splitext(os.path.basename(xfile.replace(\"magfieldx\", \"magfield\")))\n",
    "    out_path = base_out_path + f\"/lic_snap{dataset}.{os.path.basename(base_out_path)}.{file_name[0]}.bmp\"\n",
    "    # print(out_path) # ./IMAGE_PATH/LIC/snap77/left/lic_snap77.left.magfield.01.14.bmp\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        yfile = xfile.replace(\"magfieldx\", \"magfieldy\")\n",
    "        props = lic.set_command(xfile, yfile, out_path)\n",
    "        # 引数の作成\n",
    "        # 実行 (1画像20分程度)\n",
    "        lic.LIC(props)\n",
    "\n",
    "        # temp ファイルの削除\n",
    "        lic.delete_tempfile(props[1], props[2])\n",
    "\n",
    "    print(\"END\", f\"{os.path.splitext(os.path.basename(xfile))[0]} 終了\")\n",
    "\n",
    "print(\"END\", f\"{dataset} 終了\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 教師データの作成\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1 ビューワの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.params import IMAGE_PATH, SRC_PATH, SIDES\n",
    "from src.processing.viewer.createViewer import _sort_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in SIDES:\n",
    "    # paths = _sort_paths(paths) # snapの命名規則をもとに時系列順に並び変える。\n",
    "    paths = glob(IMAGE_PATH + f\"/LIC/snap{dataset}/{size}/*.bmp\")\n",
    "    paths_sorted = _sort_paths(paths)\n",
    "\n",
    "    # viewer用のファイル列を作成する\n",
    "    path_list_str = \"\\n\"\n",
    "    for path in paths_sorted:\n",
    "        path_str = path.replace(\"\\\\\", \"/\")\n",
    "        path_list_str += f\"\\t\\t\\t'{path_str}', \\n\"\n",
    "\n",
    "    # html の読み込み\n",
    "    with open(SRC_PATH + \"/Processing/viewer/template/viewer_template.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    # 可視化した.bmpのpathの一覧をhtml に追記\n",
    "    html = html.replace(\"{ replaceblock }\", path_list_str)\n",
    "\n",
    "    # html の保存\n",
    "    out_name = SRC_PATH + f\"/Processing/viewer/template/lic_viewer{dataset}.{size}.html\"\n",
    "    with open(out_name, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2 画像の分割\n",
    "\n",
    "`python ./src/Processing/viewer/writer.py`  \n",
    "を実行し、  \n",
    "`./src/Processing/viewer/template/lic_viewer77.html`\n",
    "を Web で開く (Drug & Drop)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 データの切り取り\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from src.config.params import ML_DATA_DIR\n",
    "from src.processing.train.make_train import _create_json, _set_default, _set_n, _set_xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 77  # 77, 497, 4949\n",
    "side = \"left\"  # left, right\n",
    "label = \"n\"  # n, x, o\n",
    "\n",
    "# ファイルの生成\n",
    "file_name = \"snap_labels\"\n",
    "if not os.path.exists(ML_DATA_DIR + f\"/LIC_labels/{file_name}.json\"):\n",
    "    _create_json(file_name)\n",
    "\n",
    "# ラベルによって処理が異なる\n",
    "if label == \"n\":  # 反応なし\n",
    "    result_dict = _set_n()\n",
    "elif label in [\"x\", \"o\"]:  # x点、o点\n",
    "    result_dict = _set_xo(dataset, side, label)\n",
    "else:  # その他\n",
    "    raise ValueError\n",
    "\n",
    "# 保存\n",
    "folder = ML_DATA_DIR + f\"/LIC_labels/{file_name}.json\"\n",
    "with open(folder, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if data == {}:\n",
    "    data = _set_default()\n",
    "\n",
    "with open(folder, \"w\", encoding=\"utf-8\") as f:\n",
    "    data[str(dataset)][side][label] = result_dict\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.params import SIDES, VARIABLE_PARAMETERS, ML_DATA_DIR, LABELS\n",
    "from src.processing.train.fusion_npy import CreateTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 77  # 77, 497, 4949\n",
    "path = ML_DATA_DIR + \"/LIC_labels/snap_labels.json\"\n",
    "\n",
    "md = CreateTrain(dataset)\n",
    "for side in SIDES:\n",
    "    for label in LABELS:\n",
    "        for val in VARIABLE_PARAMETERS:\n",
    "            md.cut_and_save_from_json(path, side, label, val)\n",
    "        md.cut_and_save_from_image(path, side, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. データの合成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from src.config.params import ML_DATA_DIR, LABELS\n",
    "from src.processing.train.fusion_npy import CreateTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 77  # 77, 497, 4949\n",
    "OUT_DIR = ML_DATA_DIR + \"/snap_files\"  # ./ML/data/snap_files\n",
    "\n",
    "md = CreateTrain(dataset)\n",
    "props_params = [\n",
    "    ([\"velocityx\", \"velocityy\", \"density\"], \"energy\", md.kernel_energy),\n",
    "]\n",
    "for val_params, out_basename, kernel in props_params:\n",
    "    for label in LABELS:  # n, x, o\n",
    "        npys_path = OUT_DIR + f\"/{val_params[0]}/point_{label}\"  # ./ML/data/snap_files/{out_basename}/point_{label}\n",
    "\n",
    "        for img_path in glob(npys_path + f\"/snap{dataset}_{val_params[0]}_*.npy\"):  # ./ML/data/snap_files/density/point_n\n",
    "            # 保存先のパスの作成\n",
    "            # ./ML/data/snap_files/density/point_n/snap77_density_left.01.10_030.150.npy\n",
    "            out_path = npys_path + f\"/{os.path.basename(img_path)}\"\n",
    "            out_path = out_path.replace(val_params[0], out_basename)\n",
    "            md.create_training(kernel, val_params, img_path, out_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 機械学習\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 機械学習\n",
    "\n",
    "- KMeans\n",
    "- kneighbors\n",
    "- linearSVC\n",
    "- rbfSVC\n",
    "- XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from src.config.params import SRC_PATH, ML_MODEL_DIR\n",
    "from src.MachineLearning.Training import SupervisedML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本情報\n",
    "training_parameter = \"density\"  # density, energy, enstrophy, pressure, magfieldx, magfieldy, velocityx, velocityy\n",
    "split_mode = \"mix\"  # sep, mixsep, mix\n",
    "split_mode_label = 0  # 0, 1, 2\n",
    "mode_name = split_mode + str(split_mode_label) if split_mode == \"sep\" else split_mode\n",
    "\n",
    "# 教師データ用パラメータ\n",
    "clf_name = \"LinearSVC\"  # kNeighbors, LinearSVC, rbfSVC, XGBoost\n",
    "test_size = 0.3\n",
    "model_random_state = 42\n",
    "\n",
    "# 学習用パラメータ設定\n",
    "with open(SRC_PATH + \"/config/fixed_parameter.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ML_FIXED_PARAM_DICT = json.load(f)\n",
    "\n",
    "with open(SRC_PATH + \"/config/tuning_parameter.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ML_TUNING_PARAM_DICT = json.load(f)\n",
    "\n",
    "tuning_params = ML_TUNING_PARAM_DICT[clf_name][mode_name][training_parameter]\n",
    "fixed_params = ML_FIXED_PARAM_DICT[clf_name]\n",
    "\n",
    "print(\"PARAMETER : \", f\"model={clf_name}, mode={split_mode}, training_parameter={training_parameter}, test_size={test_size}, random_state={model_random_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 初回学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SupervisedML(training_parameter=training_parameter)\n",
    "model.set_default(training_parameter)\n",
    "\n",
    "print(\"Learning  : \", \"教師データ作成\")\n",
    "model.split_train_test(split_mode)\n",
    "\n",
    "print(\"Learning  : \", \"学習開始\")\n",
    "model.do_learning(clf_name=clf_name, fixed_params=fixed_params, tuning_params=tuning_params)\n",
    "\n",
    "print(\"SAVE      : \", \"学習結果の保存\")\n",
    "model.save_npys()  # 教師データの保存  # ML\\mdoels\\npz\\ 配下に保存\n",
    "model.save_model()  # モデルの保存  # ML\\mdoels\\model\\{split_mode}\\{clf_name}\\ 配下に保存\n",
    "\n",
    "print(\"PREDICT   : \", \"予測\")\n",
    "model.predict()  # テストデータで実行\n",
    "model.print_scores()  # スコアの可視化  # ML\\result\\{clf_name}\\ 配下の .txtファイルに保存\n",
    "\n",
    "print(\"END       : \", \"処理終了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 教師データ作成済\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOAD      : \", \"データの読み込み\")\n",
    "model = SupervisedML.load_npys(split_mode=split_mode, training_parameter=training_parameter, test_size=test_size, random_state=model_random_state)\n",
    "\n",
    "print(\"Learning  : \", f\"学習開始 ({clf_name})\")\n",
    "model.do_learning(clf_name=clf_name, fixed_params=fixed_params, tuning_params=tuning_params)\n",
    "\n",
    "print(\"SAVE      : \", \"学習結果の保存\")\n",
    "model.save_model()  # モデルの保存  # ML\\mdoels\\model\\{split_mode}\\{clf_name}\\ 配下に保存\n",
    "\n",
    "print(\"PREDICT   : \", \"予測\")\n",
    "model.predict()  # テストデータで実行\n",
    "model.print_scores()  # スコアの可視化  # ML\\result\\{clf_name}\\ 配下の .txtファイルに保存\n",
    "\n",
    "print(\"END       : \", \"処理終了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル作成済\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOAD\", f\"モデルの読み込み ({clf_name})\")\n",
    "path = ML_MODEL_DIR + f\"/model/{split_mode}/model_{clf_name}_{training_parameter}_{mode_name}.C={tuning_params['C']}.sav\"\n",
    "model = SupervisedML.load_model(training_parameter=training_parameter, split_mode=split_mode, split_mode_label=split_mode_label, load_path=path)\n",
    "\n",
    "print(\"PREDICT\", \"予測\")\n",
    "model.predict()  # テストデータで実行\n",
    "model.print_scores()  # スコアの可視化  # ML\\result\\{clf_name}\\ 配下の .txtファイルに保存\n",
    "\n",
    "print(\"END       : \", \"処理終了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.params import ML_MODEL_DIR\n",
    "from src.MachineLearning.CNN import CnnTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameter = \"density\"  # density, energy, enstrophy, pressure, magfieldx, magfieldy, velocityx, velocityy\n",
    "split_mode = \"mix\"  # sep, mixsep, mix\n",
    "split_mode_label = 0  # 0, 1, 2\n",
    "mode_name = split_mode + str(split_mode_label) if split_mode == \"sep\" else split_mode\n",
    "print(\"PARAMETER : \", f\"model={clf_name}, training_parameter={training_parameter}, mode={split_mode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOAD      : \", \"データの読み込み\")\n",
    "model = CnnTrain(training_parameter=training_parameter, split_mode=split_mode, split_mode_label=split_mode_label)\n",
    "model.set_net()\n",
    "model.set_train(seed=42)\n",
    "\n",
    "print(\"Learning  : \", f\"学習開始 ({clf_name})\")\n",
    "EPOCH = 100\n",
    "model.run(epoch_cnt=EPOCH, do_plot=True)\n",
    "\n",
    "print(\"PREDICT   : \", \"予測\")\n",
    "model.predict() #\n",
    "model.print_scores()\n",
    "\n",
    "print(\"SAVE      : \", \"学習結果の保存\")\n",
    "model.save_model()  # モデルの保存 # ML\\mdoels\\model\\{split_mode}\\{clf_name} 配下に保存\n",
    "\n",
    "print(\"END       : \", \"処理終了\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル作成済\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOAD      : \", \"モデルの読み込み\")\n",
    "model_path = ML_MODEL_DIR + f\"/model/{split_mode}/model_cnn_npy_{training_parameter}_{mode_name}.save=model.device=cuda.pth\"\n",
    "model = CnnTrain.load_model(training_parameter=training_parameter, split_mode=split_mode, split_mode_label=split_mode_label, load_path=model_path)\n",
    "model.set_train(seed=42)\n",
    "\n",
    "print(\"PREDICT   : \", \"予測\")\n",
    "model.predict()  # テストデータで実行\n",
    "model.print_scores()  # スコアの可視化  # ML\\result\\{clf_name} 配下の .txtファイルに保存\n",
    "\n",
    "print(\"END       : \", \"処理終了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_kn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
