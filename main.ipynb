{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 研究の流れ\n",
    "\n",
    "この ipynb と README.md を見るだけで流れがわかるようにしました。  \n",
    "なお、各処理の詳細が知りたい場合は各ファイル、Docstring, [README.md](./README.md), [Notion](https://vizlabstudent.notion.site/de778517ea47444c9598d1f5147d78da?v=9dd0c88c9540426db2fa5a4308baf536&pvs=4)を閲覧してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準モジュールのインポート\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "from glob import glob\n",
    "\n",
    "# src配下のファイルを読み込めるようにする\n",
    "sys.path.append(os.getcwd() + \"/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通する自作モジュールのインポート\n",
    "from Visualization.SnapData import SnapData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリの作成と定義\n",
    "from config.params import ROOT_DIR, SNAP_PATH, SRC_PATH, IMAGE_PATH, ML_DATA_DIR, ML_RESULT_DIR, datasets, variable_parameters\n",
    "\n",
    "data_dir = ROOT_DIR + \"/data\"\n",
    "\n",
    "# 出力先フォルダの作成\n",
    "subprocess.run([ROOT_DIR + \"/etc/BasePath.bat\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データの加工\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 元データを各種パラメータに分割する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import subprocess\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from config.params import BIN_PATH, ROOT_DIR, SNAP_PATH, SRC_PATH, datasets\n",
    "from Processing.separatorLoop import move_file, rename_file, set_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの定義\n",
    "items1 = [\"density\", \"enstrophy\", \"pressure\", \"magfieldx\", \"magfieldy\", \"magfieldz\", \"velocityx\", \"velocityy\", \"velocityz\"]\n",
    "items2 = [\"magfield1\", \"magfield2\", \"magfield3\", \"velocity1\", \"velocity2\", \"velocity3\"]\n",
    "xyz = {1: \"x\", 2: \"y\", 3: \"z\"}\n",
    "\n",
    "for dataset in datasets:\n",
    "    ij = set_ij(dataset)\n",
    "    if ij:\n",
    "        i, j = ij\n",
    "    else:\n",
    "        print(\"Value Error\", \"入力したデータセットは使用できません\")\n",
    "        sys.exit()\n",
    "\n",
    "    # bat ファイルの実行\n",
    "    # 基本的に加工したデータの保存先のフォルダの作成\n",
    "    print(\"MAKE\", \"ディレクトリの作成\")\n",
    "    subprocess.run([BIN_PATH + \"/Snaps.bat\", str(dataset)])\n",
    "\n",
    "    # ログの保存先\n",
    "    files = glob(ROOT_DIR + f\"/data/ICh.dataset=50.ares=1.0d-{i}.adiffArt=1.0d-{j}.h00.g00.BCv1=0.0/Snapshots/*\")\n",
    "    for file in files:\n",
    "        # 元データの分割処理の実行\n",
    "        subprocess.run([SRC_PATH + \"/Processing/cln/separator.exe\", f\"{file}\"])\n",
    "        _, _, _, param, job = map(lambda x: int(x) if x.isnumeric() else x, os.path.basename(file).split(\".\"))\n",
    "        print(\"OPEN\", f\"File snap{i}{j}.{param:02d}.{job:02d}\")\n",
    "\n",
    "        # 出力されたファイル名の変更\n",
    "        for item2 in items2:\n",
    "            if os.path.exists(item2):\n",
    "                rename_file(xyz, param, job, item2)\n",
    "\n",
    "            else:  # 見つからない場合\n",
    "                print(\"NotFound\", f\"ファイル {item2}.{param:02d}.{job:02d}\")\n",
    "\n",
    "        # 出力されたファイルの移動\n",
    "        for item1 in items1:\n",
    "            if os.path.exists(item1):\n",
    "                move_file(dataset, item1)\n",
    "\n",
    "            else:  # 見つからない場合\n",
    "                print(\"NotFound\", f\"ファイル {item2}.{param:02d}.{job:02d}\")\n",
    "\n",
    "        print(\"CLOSE\", f\"File {item2}.{param:02d}.{job:02d}\")\n",
    "\n",
    "    # coordn を最後に移動させる\n",
    "    for i in range(1, 4):\n",
    "        shutil.move(\"coord\" + xyz[i], SNAP_PATH + f\"/snap{dataset}\")\n",
    "\n",
    "    print(\"END\", \"処理終了\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 バイナリを .npy に変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from config.params import SNAP_PATH, datasets, variable_parameters, set_dataset\n",
    "from Processing.snap2npy import snap2npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "sp = SnapData()\n",
    "print(\"START\", f\"Snap{dataset} 開始\")\n",
    "\n",
    "for param in variable_parameters:\n",
    "    print(\"START\", f\"{param} 開始\")\n",
    "\n",
    "    for path in glob(SNAP_PATH + f\"/snap{dataset}/{param}/*/*\"):\n",
    "        # print(path)\n",
    "        snap2npy(sp, path, dataset)\n",
    "\n",
    "    print(\"END\", f\"{param} 終了\")\n",
    "print(\"END\", f\"Snap{dataset} 終了\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 可視化\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 各種可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from config.params import SNAP_PATH, datasets\n",
    "from Visualization.Visualize import VisualizeMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "target_path = SNAP_PATH + f\"/snap{dataset}\"\n",
    "viz = VisualizeMethod(dataset)\n",
    "\n",
    "files = {}\n",
    "files[\"density\"] = glob(target_path + f\"/density/*/*\")\n",
    "files[\"velocityx\"] = glob(target_path + f\"/velocityx/*/*\")\n",
    "files[\"velocityy\"] = glob(target_path + f\"/velocityy/*/*\")\n",
    "for dens_path, vx_path, vy_path in zip(files[\"density\"], files[\"velocityx\"], files[\"velocityy\"]):\n",
    "    viz.drawEnergy_for_velocity(dens_path, vx_path, vy_path)\n",
    "\n",
    "files[\"magfieldx\"] = glob(target_path + f\"/magfieldx/*/*\")\n",
    "files[\"magfieldy\"] = glob(target_path + f\"/magfieldy/*/*\")\n",
    "for magx_path, magy_path in zip(files[\"magfieldx\"], files[\"magfieldy\"]):\n",
    "    viz.drawEnergy_for_magfield(magx_path, magy_path)\n",
    "\n",
    "files[\"enstrophy\"] = glob(target_path + f\"/enstrophy/*/*\")\n",
    "for target in [\"velocityx\", \"velocityy\", \"magfieldx\", \"magfieldy\", \"density\", \"enstrophy\"]:\n",
    "    for path in files[target]:\n",
    "        viz.drawHeatmap(path)\n",
    "        viz.drawEdge(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 AVS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 StreamLines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 LIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from config.params import SNAP_PATH, IMAGE_PATH, datasets\n",
    "from LIC.LIC import LicMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログ取得の開始\n",
    "print(\"START\", \"処理開始\\n\\n\")\n",
    "\n",
    "dataset = set_dataset(input())\n",
    "size = \"left\" # right\n",
    "\n",
    "print(\"START\", f\"{dataset}.{size.split('_')[1]} 開始\\n\")\n",
    "lic = LicMethod()\n",
    "\n",
    "# 入出力用path の作成\n",
    "in_dir = SNAP_PATH + f\"/{size}/snap{dataset}\"\n",
    "dir_basename = os.path.basename(in_dir)  # snap77\n",
    "out_dir = IMAGE_PATH + \"/LIC\"\n",
    "base_out_path = out_dir + \"/\" + os.path.basename(in_dir) + \"/\" + size.split(\"_\")[1]  # ./IMAGES/LIC/snap77/left\n",
    "lic.makedir(f\"/LIC/snap{dataset}/{size.split('_')[1]}\")\n",
    "\n",
    "# バイナリファイルの取得\n",
    "binary_paths = glob(in_dir + \"/magfieldx/*/*.npy\")\n",
    "\n",
    "# ファイルが無い場合\n",
    "if binary_paths == []:\n",
    "    print(\"ERROR\", \"File not Found\\n\")\n",
    "    sys.exit()\n",
    "\n",
    "for xfile in binary_paths:\n",
    "    print(\"START\", f\"{os.path.splitext(os.path.basename(xfile))[0]} 開始\\n\")\n",
    "    yfile = xfile.replace(\"magfieldx\", \"magfieldy\")\n",
    "    file_name = os.path.splitext(os.path.basename(xfile.replace(\"magfieldx\", \"magfield\")))\n",
    "    out_path = base_out_path + f\"/lic_{dir_basename}.{os.path.basename(base_out_path)}.{file_name[0]}.bmp\"\n",
    "    # print(out_path) # ./IMAGES/LIC/snap77/lic_snap77.magfieldx.01.14.bmp\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        # 引数の作成\n",
    "        props = lic.set_command(xfile, yfile, out_path)\n",
    "        # 実行 (1画像20分程度)\n",
    "        lic.LIC(props)\n",
    "\n",
    "        # temp ファイルの削除\n",
    "        lic.delete_tempfile(props[1], props[2])\n",
    "\n",
    "    print(\"END\", f\"{os.path.splitext(os.path.basename(xfile))[0]} 終了\\n\")\n",
    "\n",
    "print(\"END\", f\"{dataset} 終了\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 教師データの作成\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1 ビューワの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from Processing.viewer.createViewer import _sort_paths\n",
    "from config.params import IMAGE_PATH, SRC_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [\"left\", \"right\"]:\n",
    "    # paths = _sort_paths(paths) # snapの命名規則をもとに時系列順に並び変える。\n",
    "    paths = glob(IMAGE_PATH + f\"/LIC/snap{dataset}/{size}/*.bmp\")\n",
    "    paths_sorted = _sort_paths(paths)\n",
    "\n",
    "    # viewer用のファイル列を作成する\n",
    "    path_list_str = \"\\n\"\n",
    "    for path in paths_sorted:\n",
    "        path_str = path.replace(\"\\\\\", \"/\")\n",
    "        path_list_str += f\"\\t\\t\\t'{path_str}', \\n\"\n",
    "\n",
    "    # html の読み込み\n",
    "    with open(SRC_PATH + \"/Processing/viewer/template/viewer_template.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    # 可視化した.bmpのpathの一覧をhtml に追記\n",
    "    html = html.replace(\"{ replaceblock }\", path_list_str)\n",
    "\n",
    "    # html の保存\n",
    "    out_name = SRC_PATH + f\"/Processing/viewer/template/lic_viewer{dataset}.{size}.html\"\n",
    "    with open(out_name, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2 画像の分割\n",
    "\n",
    "`python ./src/Processing/viewer/writer.py`  \n",
    "を実行し、  \n",
    "`./src/Processing/viewer/template/lic_viewer77.html`\n",
    "を Web で開く (Drug & Drop)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 データの切り取り\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "\n",
    "from config.params import set_dataset\n",
    "from Processing.fusion_npy import CrateTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "md = CrateTrain()\n",
    "for val in [\"magfieldx\", \"magfieldy\", \"velocityx\", \"velocityy\", \"density\"]:\n",
    "    md.cut_and_save(dataset, val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. データの合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.getcwd() + \"/src\")\n",
    "from config.params import ML_DATA_DIR, labels, set_dataset\n",
    "from Processing.fusion_npy import CrateTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = set_dataset(input())\n",
    "\n",
    "md = CrateTrain()\n",
    "props_params = [\n",
    "    ([\"magfieldx\", \"magfieldy\"], \"mag_tupledxy\", md.kernellistxy),\n",
    "    ([\"velocityx\", \"velocityy\", \"density\"], \"energy\", md.kernelEnergy),\n",
    "]\n",
    "OUT_DIR = ML_DATA_DIR + f\"/snap{dataset}\"\n",
    "\n",
    "# /images/0131_not/density/density_49.50.8_9.528\n",
    "for val_params, out_basename, kernel in props_params:\n",
    "    for label in labels:\n",
    "        npys = OUT_DIR + f\"/point_{label}\"\n",
    "\n",
    "        for img_path in glob(npys + \"/\" + val_params[0] + \"/*.npy\"):\n",
    "            im_list = md.loadBinaryData(img_path, val_params)  # 混合データのロード\n",
    "            resim = kernel(*im_list)  # データの作成\n",
    "\n",
    "            # 保存先のパスの作成\n",
    "            # /MLdata/snap{dataset}/{out_basename}/{out_basename}_{dataset}.{param}.{job}_{centerx}.{centery}.npy\n",
    "            # /MLdata/snap77/energy/energy_77.01.03_131.543.npy\n",
    "            out_path = npys + \"/\" + out_basename + \"/\" + os.path.basename(img_path).replace(val_params[0], out_basename)\n",
    "            md.saveFusionData(resim, out_path)  # データの保存\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 機械学習\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 k-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getcwd() + \"\\src\")\n",
    "\n",
    "from config.params import SNAP_PATH, datasets, variable_parameters\n",
    "from MachineLearning.KMeans import ClusteringMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = ClusteringMethod()\n",
    "\n",
    "for dataset in datasets:\n",
    "    for target in variable_parameters:\n",
    "        path_list = glob(SNAP_PATH + f\"/snap{dataset}/{target}/*/*\")\n",
    "        num_of_data = len(path_list)  # リコネクションがない画像の枚数\n",
    "\n",
    "        temp_data = cluster.compress(cluster.loadSnapData(path_list[0], z=3))\n",
    "        IMGSHAPE = temp_data.shape\n",
    "\n",
    "        N_col = IMGSHAPE[0] * IMGSHAPE[1] * 1  # 行列の列数\n",
    "        X_train = np.zeros((num_of_data, N_col))  # 学習データ格納のためゼロ行列生成\n",
    "        y_train = np.zeros((num_of_data))  # 学習データに対するラベルを格納するためのゼロ行列生成\n",
    "\n",
    "        # リコネクションがない画像を行列に読み込む\n",
    "        for idx, item in enumerate(path_list[:10]):\n",
    "            X_train[idx, :] = cluster.load_regularize(item)\n",
    "            y_train[idx] = 0  # リコネクションがないことを表すラベル\n",
    "\n",
    "        X_train_pca = cluster.PCA(X_train)\n",
    "        cluster_labels = cluster.KMeans(X_train_pca)\n",
    "        df_re = cluster.save_result(cluster_labels, path_list, dataset)\n",
    "        # display(df_re)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 非線形 SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 k 近傍法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_kn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
